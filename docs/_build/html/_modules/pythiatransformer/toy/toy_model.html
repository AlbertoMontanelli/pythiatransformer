<!DOCTYPE html>
<html lang="en"
      data-content_root="../../../"
      x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }"
      x-init="$watch('darkMode', val => localStorage.setItem('darkMode', val))"
      class="scroll-smooth"
      :class="{'dark': darkMode === 'dark' || (darkMode === 'system' && window.matchMedia('(prefers-color-scheme: dark)').matches)}"
>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta charset="utf-8" />
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="white" />
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="black" />
  
    <title>pythiatransformer.toy.toy_model | pythiatransformer 0.1.0 documentation</title>
    <meta property="og:title" content="pythiatransformer.toy.toy_model | pythiatransformer 0.1.0 documentation" />
    <meta name="twitter:title" content="pythiatransformer.toy.toy_model | pythiatransformer 0.1.0 documentation" />
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/theme.css?v=42baaae4" />
        <link rel="search" title="Search" href="../../../search.html" />
        <link rel="index" title="Index" href="../../../genindex.html" />

    <script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
  <body x-data="{ showSidebar: false, showScrollTop: false }" class="min-h-screen font-sans antialiased bg-background text-foreground" :class="{ 'overflow-hidden': showSidebar }">
    <div x-cloak x-show="showSidebar" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" @click.self="showSidebar = false"></div><div id="page" class="relative flex flex-col min-h-screen"><a href="#content" class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100">
      Skip to content
    </a><header
  class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
    <div class="hidden mr-4 md:flex">
      <a href="../../../index.html" class="flex items-center mr-6"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">pythiatransformer 0.1.0 documentation</span>
      </a></div><button
      class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden"
      type="button" @click="showSidebar = true">
      <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" aria-hidden="true"
        fill="currentColor">
        <path
          d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z" />
      </svg>
      <span class="sr-only">Toggle navigation menu</span>
    </button>
    <div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
      <div class="flex-1 w-full md:w-auto md:flex-none"><form id="searchbox"
      action="../../../search.html"
      method="get"
      class="relative flex items-center group"
      @keydown.k.window.meta="$refs.search.focus()">
  <input x-ref="search"
          name="q"
          id="search-input"
          type="search"
          aria-label="Search the docs"
          placeholder="Search ..."
          class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" />
  <kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
    <span class="text-xs">âŒ˜</span>
    K
  </kbd>
</form>
      </div>
      <nav class="flex items-center space-x-1">
        <button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'"
          class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9"
          type="button"
          aria-label="Color theme switcher">
          <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
            class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0">
            <path
              d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z" />
          </svg>
          <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
            class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100">
            <path
              d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z" />
          </svg>
        </button>
      </nav>
    </div>
  </div>
</header>

    <div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside id="left-sidebar"
  class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky"
  :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }">

    <a href="../../../index.html" class="!justify-start text-sm md:!hidden bg-background"><span class="font-bold text-clip whitespace-nowrap">pythiatransformer 0.1.0 documentation</span>
    </a>

    <div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
      <div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../name_convention.html">Naming conventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rep_structure.html">Repository structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_api/modules.html">pythiatransformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_api/tests_index.html">tests</a></li>
</ul>
</li>
</ul>

</nav>
      </div>
    </div>
    <button type="button" @click="showSidebar = false"
      class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100">
      <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
        stroke="none" class="h-4 w-4">
        <path
          d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z" />
      </svg>
    </button>
  </aside>
        <main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs"
     class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
  <a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground"
     href="../../../index.html">
    <span class="hidden md:inline">pythiatransformer 0.1.0 documentation</span>
    <svg xmlns="http://www.w3.org/2000/svg"
         height="18"
         width="18"
         viewBox="0 96 960 960"
         aria-label="Home"
         fill="currentColor"
         stroke="none"
         class="md:hidden">
      <path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z" />
    </svg>
  </a>
  
<div class="mr-1">/</div><a class="hover:text-foreground overflow-hidden text-ellipsis whitespace-nowrap"
       href="../../index.html">Module code</a>
    
<div class="mr-1">/</div><span aria-current="page"
        class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">pythiatransformer.toy.toy_model</span>
</nav>

    <div id="content" role="main">
      <h1>Source code for pythiatransformer.toy.toy_model</h1><div class="highlight"><pre>
<span></span><code><span id="line-1"><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-2"><span class="sd">Custom transformer model and training script for a toy regression task.</span>
</span><span id="line-3">
</span><span id="line-4"><span class="sd">This script implements a simple regression task using a transformer</span>
</span><span id="line-5"><span class="sd">architecture. Given a single float input ``x``, the model learns to</span>
</span><span id="line-6"><span class="sd">generate a sequence of values ``[y_1, y_2, ..., y_k]`` such that the</span>
</span><span id="line-7"><span class="sd">sum of the sequence equals ``x``, with optional zero-padding up to a</span>
</span><span id="line-8"><span class="sd">fixed maximum length.</span>
</span><span id="line-9"><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-10">
</span><span id="line-11"><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</span><span id="line-12"><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
</span><span id="line-13">
</span><span id="line-14"><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</span><span id="line-15"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="line-16"><span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
</span><span id="line-17"><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span id="line-18"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
</span><span id="line-19">
</span><span id="line-20">
</span><span id="line-21"><span class="k">def</span><span class="w"> </span><span class="nf">_check_type</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
</span><span id="line-22"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Check whether a variable is of the expected type.&quot;&quot;&quot;</span>
</span><span id="line-23">    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
</span><span id="line-24">        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="line-25">            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> must be of type </span><span class="si">{</span><span class="n">t</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">var</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="line-26">        <span class="p">)</span>
</span><span id="line-27">
</span><span id="line-28">
<div class="viewcode-block" id="plot_learning_curve">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.plot_learning_curve">[docs]</a>
</span><span id="line-29"><span class="k">def</span><span class="w"> </span><span class="nf">plot_learning_curve</span><span class="p">(</span>
</span><span id="line-30">    <span class="n">train_loss</span><span class="p">,</span>
</span><span id="line-31">    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;toy_learning_curve.pdf&quot;</span><span class="p">,</span>
</span><span id="line-32">    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Learning Curve&quot;</span><span class="p">,</span>
</span><span id="line-33">    <span class="n">dpi</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span>
</span><span id="line-34"><span class="p">):</span>
</span><span id="line-35"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-36"><span class="sd">    Plot and save the training and validation loss curves over epochs.</span>
</span><span id="line-37">
</span><span id="line-38"><span class="sd">    Parameters</span>
</span><span id="line-39"><span class="sd">    ----------</span>
</span><span id="line-40"><span class="sd">    train_loss : list[float]</span>
</span><span id="line-41"><span class="sd">        Training loss values.</span>
</span><span id="line-42"><span class="sd">    filename: str</span>
</span><span id="line-43"><span class="sd">        File name to save the plot.</span>
</span><span id="line-44"><span class="sd">    title: str</span>
</span><span id="line-45"><span class="sd">        Title of the plot.</span>
</span><span id="line-46"><span class="sd">    dpi: int</span>
</span><span id="line-47"><span class="sd">        Resolution of the saved figure.</span>
</span><span id="line-48"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="line-49">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
</span><span id="line-50">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">)</span>
</span><span id="line-51">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
</span><span id="line-52">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
</span><span id="line-53">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</span><span id="line-54">    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span><span id="line-55">    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-56">    <span class="n">base_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span>
</span><span id="line-57">    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">base_dir</span> <span class="o">/</span> <span class="n">filename</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">dpi</span><span class="p">)</span>
</span><span id="line-58">    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="line-59">    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learning curve saved as </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

</span><span id="line-60">
</span><span id="line-61">
<div class="viewcode-block" id="ToyDataset">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyDataset">[docs]</a>
</span><span id="line-62"><span class="k">class</span><span class="w"> </span><span class="nc">ToyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
</span><span id="line-63"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-64"><span class="sd">    Prepare the dataset for a toy regression task.</span>
</span><span id="line-65">
</span><span id="line-66"><span class="sd">    Each sample consists of:</span>
</span><span id="line-67">
</span><span id="line-68"><span class="sd">    - input scalar ``x`` sampled uniformly from (0, 10);</span>
</span><span id="line-69"><span class="sd">    - target sequence ``(y_1, ..., y_k)`` whose sum equals ``x``, with</span>
</span><span id="line-70"><span class="sd">      random length ``k`` in ``[1, max_len]``; zero-padded</span>
</span><span id="line-71"><span class="sd">      to ``max_len``;</span>
</span><span id="line-72"><span class="sd">    - boolean mask for valid (non-padded) elements.</span>
</span><span id="line-73">
</span><span id="line-74"><span class="sd">    The goal is to teach models to decompose a scalar into a positive</span>
</span><span id="line-75"><span class="sd">    sequence that sums to it.</span>
</span><span id="line-76"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="line-77">
<div class="viewcode-block" id="ToyDataset.__init__">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyDataset.__init__">[docs]</a>
</span><span id="line-78">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
</span><span id="line-79"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-80"><span class="sd">        Class constructor.</span>
</span><span id="line-81">
</span><span id="line-82"><span class="sd">        Parameters</span>
</span><span id="line-83"><span class="sd">        ----------</span>
</span><span id="line-84"><span class="sd">        n_samples: int</span>
</span><span id="line-85"><span class="sd">            Number of samples to generate.</span>
</span><span id="line-86"><span class="sd">        max_len: int</span>
</span><span id="line-87"><span class="sd">            Maximum sequence length for the target y.</span>
</span><span id="line-88"><span class="sd">        seed: int</span>
</span><span id="line-89"><span class="sd">            Random seed for reproducibility.</span>
</span><span id="line-90"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-91">        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="line-92">        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span><span id="line-93">        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>
</span><span id="line-94">        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-95">        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
</span><span id="line-96">            <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
</span><span id="line-97">            <span class="n">k</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
</span><span id="line-98">
</span><span id="line-99">            <span class="c1"># Create a tensor 1D of length k with values in [0,1].</span>
</span><span id="line-100">            <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span><span id="line-101">            <span class="c1"># Normalize v to sum=1, then scale by x to decompose it</span>
</span><span id="line-102">            <span class="c1"># into y.</span>
</span><span id="line-103">            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span> <span class="o">/</span> <span class="n">v</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="line-104">            <span class="n">y</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">x</span>
</span><span id="line-105">            <span class="c1"># Create padded data tensor and padding mask.</span>
</span><span id="line-106">            <span class="n">y_pad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
</span><span id="line-107">            <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
</span><span id="line-108">            <span class="n">y_pad</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
</span><span id="line-109">            <span class="n">mask</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="line-110">            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y_pad</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span></div>

</span><span id="line-111">
<div class="viewcode-block" id="ToyDataset.__len__">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyDataset.__len__">[docs]</a>
</span><span id="line-112">    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="line-113"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-114"><span class="sd">        Return the total number of samples in the dataset.</span>
</span><span id="line-115">
</span><span id="line-116"><span class="sd">        Returns</span>
</span><span id="line-117"><span class="sd">        -------</span>
</span><span id="line-118"><span class="sd">        len: int</span>
</span><span id="line-119"><span class="sd">            The number of samples.</span>
</span><span id="line-120"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-121">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></div>

</span><span id="line-122">
<div class="viewcode-block" id="ToyDataset.__getitem__">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyDataset.__getitem__">[docs]</a>
</span><span id="line-123">    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
</span><span id="line-124"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-125"><span class="sd">        Retrieve the sample at the given index.</span>
</span><span id="line-126">
</span><span id="line-127"><span class="sd">        Parameters</span>
</span><span id="line-128"><span class="sd">        ----------</span>
</span><span id="line-129"><span class="sd">        idx: int</span>
</span><span id="line-130"><span class="sd">            Index of the sample to retrieve.</span>
</span><span id="line-131">
</span><span id="line-132"><span class="sd">        Returns</span>
</span><span id="line-133"><span class="sd">        -------</span>
</span><span id="line-134"><span class="sd">        x: torch.Tensor</span>
</span><span id="line-135"><span class="sd">            Scalar input.</span>
</span><span id="line-136"><span class="sd">        y_pad: torch.Tensor</span>
</span><span id="line-137"><span class="sd">            Target sequence.</span>
</span><span id="line-138"><span class="sd">        mask: torch.Tensor</span>
</span><span id="line-139"><span class="sd">            Boolean mask indicating valid (non-padded) elements.</span>
</span><span id="line-140"><span class="sd">        length: int</span>
</span><span id="line-141"><span class="sd">            Actual sequence length before padding.</span>
</span><span id="line-142"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-143">        <span class="n">x</span><span class="p">,</span> <span class="n">y_pad</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span><span id="line-144">        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">y_pad</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">length</span></div>
</div>

</span><span id="line-145">
</span><span id="line-146">
<div class="viewcode-block" id="ToyTransformer">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyTransformer">[docs]</a>
</span><span id="line-147"><span class="k">class</span><span class="w"> </span><span class="nc">ToyTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="line-148"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-149"><span class="sd">    Custom transformer model for the toy regression task.</span>
</span><span id="line-150">
</span><span id="line-151"><span class="sd">    Implements a toy transformer model for sequential regression.</span>
</span><span id="line-152"><span class="sd">    The model takes as input a scalar x and learns to generate a</span>
</span><span id="line-153"><span class="sd">    sequence of positive values that sum approximately to x. It uses</span>
</span><span id="line-154"><span class="sd">    a transformer architecture with encoder-decoder structure.</span>
</span><span id="line-155"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="line-156">
<div class="viewcode-block" id="ToyTransformer.__init__">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyTransformer.__init__">[docs]</a>
</span><span id="line-157">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="line-158">        <span class="bp">self</span><span class="p">,</span>
</span><span id="line-159">        <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-160">        <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="line-161">        <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="line-162">        <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="line-163">        <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="line-164">        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="line-165">        <span class="n">max_len</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="line-166">    <span class="p">):</span>
</span><span id="line-167"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-168"><span class="sd">        Class constructor.</span>
</span><span id="line-169">
</span><span id="line-170"><span class="sd">        Parameters</span>
</span><span id="line-171"><span class="sd">        ----------</span>
</span><span id="line-172"><span class="sd">        d_model: int</span>
</span><span id="line-173"><span class="sd">            Dimensionality of the internal representation.</span>
</span><span id="line-174"><span class="sd">        nhead: int</span>
</span><span id="line-175"><span class="sd">            Number of attention heads.</span>
</span><span id="line-176"><span class="sd">        num_encoder_layers: int</span>
</span><span id="line-177"><span class="sd">            Number of encoder layers.</span>
</span><span id="line-178"><span class="sd">        num_decoder_layers: int</span>
</span><span id="line-179"><span class="sd">            Number of decoder layers.</span>
</span><span id="line-180"><span class="sd">        dim_feedforward: int,</span>
</span><span id="line-181"><span class="sd">            Dimension of the feedforward network.</span>
</span><span id="line-182"><span class="sd">        dropout: float</span>
</span><span id="line-183"><span class="sd">            Dropout probability.</span>
</span><span id="line-184"><span class="sd">        max_len: int</span>
</span><span id="line-185"><span class="sd">            Maximum output sequence length.</span>
</span><span id="line-186"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-187">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="line-188">        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span><span id="line-189">        <span class="bp">self</span><span class="o">.</span><span class="n">nhead</span> <span class="o">=</span> <span class="n">nhead</span>
</span><span id="line-190">        <span class="bp">self</span><span class="o">.</span><span class="n">num_encoder_layers</span> <span class="o">=</span> <span class="n">num_encoder_layers</span>
</span><span id="line-191">        <span class="bp">self</span><span class="o">.</span><span class="n">num_decoder_layers</span> <span class="o">=</span> <span class="n">num_decoder_layers</span>
</span><span id="line-192">        <span class="bp">self</span><span class="o">.</span><span class="n">dim_feedforward</span> <span class="o">=</span> <span class="n">dim_feedforward</span>
</span><span id="line-193">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</span><span id="line-194">        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>
</span><span id="line-195">
</span><span id="line-196">        <span class="n">_check_type</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="s2">&quot;d_model&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="line-197">        <span class="n">_check_type</span><span class="p">(</span><span class="n">nhead</span><span class="p">,</span> <span class="s2">&quot;nhead&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="line-198">        <span class="n">_check_type</span><span class="p">(</span><span class="n">num_encoder_layers</span><span class="p">,</span> <span class="s2">&quot;num_encoder_layers&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="line-199">        <span class="n">_check_type</span><span class="p">(</span><span class="n">num_decoder_layers</span><span class="p">,</span> <span class="s2">&quot;num_decoder_layers&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="line-200">        <span class="n">_check_type</span><span class="p">(</span><span class="n">dim_feedforward</span><span class="p">,</span> <span class="s2">&quot;dim_feedforward&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="line-201">        <span class="n">_check_type</span><span class="p">(</span><span class="n">dropout</span><span class="p">,</span> <span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
</span><span id="line-202">        <span class="n">_check_type</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="s2">&quot;max_len&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="line-203">
</span><span id="line-204">        <span class="k">if</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">nhead</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="line-205">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;d_model must be a multiple of nhead.&quot;</span><span class="p">)</span>
</span><span id="line-206">        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">dropout</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="line-207">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dropout must be between 0.0 and 1.0&quot;</span><span class="p">)</span>
</span><span id="line-208">        <span class="k">if</span> <span class="n">max_len</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="line-209">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max_len must be &gt; 0, got </span><span class="si">{</span><span class="n">max_len</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-210">
</span><span id="line-211">        <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>  <span class="c1"># Embedding in d_model.</span>
</span><span id="line-212">        <span class="c1"># Learnable start-of-sequence token.</span>
</span><span id="line-213">        <span class="bp">self</span><span class="o">.</span><span class="n">sos_token</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
</span><span id="line-214">        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="p">(</span>
</span><span id="line-215">            <span class="n">d_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
</span><span id="line-216">            <span class="n">nhead</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nhead</span><span class="p">,</span>
</span><span id="line-217">            <span class="n">num_encoder_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_encoder_layers</span><span class="p">,</span>
</span><span id="line-218">            <span class="n">num_decoder_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_decoder_layers</span><span class="p">,</span>
</span><span id="line-219">            <span class="n">dim_feedforward</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim_feedforward</span><span class="p">,</span>
</span><span id="line-220">            <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="line-221">            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="line-222">        <span class="p">)</span>
</span><span id="line-223">        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="line-224">        <span class="c1"># Head to predict the end-of-sequence (EOS) probability.</span>
</span><span id="line-225">        <span class="bp">self</span><span class="o">.</span><span class="n">stop_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>

</span><span id="line-226">
<div class="viewcode-block" id="ToyTransformer.forward_teacher">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyTransformer.forward_teacher">[docs]</a>
</span><span id="line-227">    <span class="k">def</span><span class="w"> </span><span class="nf">forward_teacher</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
</span><span id="line-228"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-229"><span class="sd">        Forward pass in teacher forcing mode.</span>
</span><span id="line-230">
</span><span id="line-231"><span class="sd">        The model receives a scalar input ``x``, a padded target</span>
</span><span id="line-232"><span class="sd">        sequence ``y`` and the corresponding padding mask.</span>
</span><span id="line-233"><span class="sd">        The decoder receives the target sequence with a special start</span>
</span><span id="line-234"><span class="sd">        of sequence (``SOS``) token. It predicts the output sequence</span>
</span><span id="line-235"><span class="sd">        and a stop signal for each step.</span>
</span><span id="line-236">
</span><span id="line-237"><span class="sd">        Parameters</span>
</span><span id="line-238"><span class="sd">        ----------</span>
</span><span id="line-239"><span class="sd">        x: torch.Tensor</span>
</span><span id="line-240"><span class="sd">            Input tensor of shape ``(B,)``.</span>
</span><span id="line-241"><span class="sd">        y: torch.Tensor</span>
</span><span id="line-242"><span class="sd">            Target padded sequences of shape ``(B, T)``.</span>
</span><span id="line-243"><span class="sd">        mask: torch.Tensor</span>
</span><span id="line-244"><span class="sd">            Boolean mask of shape ``(B, T)``, where ``True`` indicates</span>
</span><span id="line-245"><span class="sd">            non-padded elements.</span>
</span><span id="line-246">
</span><span id="line-247"><span class="sd">        Returns</span>
</span><span id="line-248"><span class="sd">        -------</span>
</span><span id="line-249"><span class="sd">        y_hat: torch.Tensor</span>
</span><span id="line-250"><span class="sd">            Predicted sequence of shape ``(B, T+1)``.</span>
</span><span id="line-251"><span class="sd">        stop_logits: torch.Tensor</span>
</span><span id="line-252"><span class="sd">            Logits for stop signalof shape ``(B, T+1)``.</span>
</span><span id="line-253"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-254">        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="line-255">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="line-256">                <span class="sa">f</span><span class="s2">&quot;x must be a 1D tensor of shape (B,), got shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="line-257">            <span class="p">)</span>
</span><span id="line-258">        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="line-259">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="line-260">                <span class="sa">f</span><span class="s2">&quot;y must be a 2D tensor of shape (B, T), got shape </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="line-261">            <span class="p">)</span>
</span><span id="line-262">        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="line-263">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="line-264">                <span class="s2">&quot;Shape mismatch: y and mask must have the same shape.&quot;</span>
</span><span id="line-265">            <span class="p">)</span>
</span><span id="line-266">
</span><span id="line-267">        <span class="n">b</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</span><span id="line-268">        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
</span><span id="line-269">        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape [B,1,d].</span>
</span><span id="line-270">        <span class="n">sos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sos_token</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape [B,1,d].</span>
</span><span id="line-271">        <span class="n">tgt_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># shape [B,T,d].</span>
</span><span id="line-272">        <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">sos</span><span class="p">,</span> <span class="n">tgt_emb</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape [B,T+1,d].</span>
</span><span id="line-273">        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="o">.</span><span class="n">generate_square_subsequent_mask</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
</span><span id="line-274">            <span class="n">device</span>
</span><span id="line-275">        <span class="p">)</span>
</span><span id="line-276">        <span class="n">src_key_padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="line-277">            <span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
</span><span id="line-278">        <span class="p">)</span>
</span><span id="line-279">        <span class="n">pad_dec</span> <span class="o">=</span> <span class="o">~</span><span class="n">mask</span>
</span><span id="line-280">        <span class="n">tgt_key_padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
</span><span id="line-281">            <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">pad_dec</span><span class="p">],</span>
</span><span id="line-282">            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="line-283">        <span class="p">)</span>
</span><span id="line-284">        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span>
</span><span id="line-285">            <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">,</span>
</span><span id="line-286">            <span class="n">tgt</span><span class="o">=</span><span class="n">tgt</span><span class="p">,</span>
</span><span id="line-287">            <span class="n">tgt_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span>
</span><span id="line-288">            <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span><span class="p">,</span>
</span><span id="line-289">            <span class="n">tgt_key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">,</span>
</span><span id="line-290">        <span class="p">)</span>  <span class="c1"># shape [B,T+1,d].</span>
</span><span id="line-291">        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape [B,T+1].</span>
</span><span id="line-292">        <span class="n">stop_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_head</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape [B,T+1].</span>
</span><span id="line-293">        <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">stop_logits</span></div>

</span><span id="line-294">
<div class="viewcode-block" id="ToyTransformer.generate">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.ToyTransformer.generate">[docs]</a>
</span><span id="line-295">    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stop_thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
</span><span id="line-296"><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-297"><span class="sd">        Autoregressive inference for sequence generation.</span>
</span><span id="line-298">
</span><span id="line-299"><span class="sd">        Starts with a special start of sequence (``SOS``) token and</span>
</span><span id="line-300"><span class="sd">        generates outputs one step at a time using the model&#39;s own</span>
</span><span id="line-301"><span class="sd">        predictions.</span>
</span><span id="line-302"><span class="sd">        Generation continues until either the maximum sequence length</span>
</span><span id="line-303"><span class="sd">        is reached or all stop probabilities exceed the given threshold.</span>
</span><span id="line-304">
</span><span id="line-305"><span class="sd">        Parameters</span>
</span><span id="line-306"><span class="sd">        ----------</span>
</span><span id="line-307"><span class="sd">        x: torch.Tensor</span>
</span><span id="line-308"><span class="sd">            Input tensor of shape ``(B,)``.</span>
</span><span id="line-309"><span class="sd">        max_len: int, default=None</span>
</span><span id="line-310"><span class="sd">            Maximum number of steps to generate. Optional, if ``None``</span>
</span><span id="line-311"><span class="sd">            uses ``self.max_len``.</span>
</span><span id="line-312"><span class="sd">        stop_thresh: float, default=0.5</span>
</span><span id="line-313"><span class="sd">            Threshold for the stop probability to end generation.</span>
</span><span id="line-314">
</span><span id="line-315"><span class="sd">        Returns</span>
</span><span id="line-316"><span class="sd">        -------</span>
</span><span id="line-317"><span class="sd">        y_seq: torch.Tensor</span>
</span><span id="line-318"><span class="sd">            Generated sequence of shape ``(B, T)``, where</span>
</span><span id="line-319"><span class="sd">            ``T â‰¤ max_len``.</span>
</span><span id="line-320"><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="line-321">        <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">stop_thresh</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span id="line-322">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="line-323">                <span class="sa">f</span><span class="s2">&quot;stop_thresh must be between 0 and 1, got </span><span class="si">{</span><span class="n">stop_thresh</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="line-324">            <span class="p">)</span>
</span><span id="line-325">
</span><span id="line-326">        <span class="k">if</span> <span class="n">max_len</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="line-327">            <span class="n">max_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span>
</span><span id="line-328">        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
</span><span id="line-329">        <span class="n">b</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="line-330">        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-331">        <span class="n">src_key_padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span><span id="line-332">            <span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
</span><span id="line-333">        <span class="p">)</span>
</span><span id="line-334">        <span class="n">tgt_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sos_token</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
</span><span id="line-335">        <span class="n">generated</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-336">        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
</span><span id="line-337">            <span class="n">tgt_mask</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="o">.</span><span class="n">generate_square_subsequent_mask</span><span class="p">(</span>
</span><span id="line-338">                <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="line-339">            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-340">            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span>
</span><span id="line-341">                <span class="n">src</span><span class="o">=</span><span class="n">src</span><span class="p">,</span>
</span><span id="line-342">                <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_emb</span><span class="p">,</span>
</span><span id="line-343">                <span class="n">tgt_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span>
</span><span id="line-344">                <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span><span class="p">,</span>
</span><span id="line-345">            <span class="p">)</span>
</span><span id="line-346">            <span class="n">last</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="line-347">            <span class="n">y_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">last</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-348">            <span class="n">p_stop</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_head</span><span class="p">(</span><span class="n">last</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-349">            <span class="n">generated</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_t</span><span class="p">)</span>
</span><span id="line-350">            <span class="n">y_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">y_t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-351">            <span class="n">tgt_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tgt_emb</span><span class="p">,</span> <span class="n">y_emb</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-352">            <span class="k">if</span> <span class="p">(</span><span class="n">p_stop</span> <span class="o">&gt;</span> <span class="n">stop_thresh</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
</span><span id="line-353">                <span class="k">break</span>
</span><span id="line-354">        <span class="n">y_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-355">        <span class="k">return</span> <span class="n">y_seq</span></div>
</div>

</span><span id="line-356">
</span><span id="line-357">
<div class="viewcode-block" id="main">
<a class="viewcode-back" href="../../../_api/pythiatransformer.toy.toy_model.html#pythiatransformer.toy.toy_model.main">[docs]</a>
</span><span id="line-358"><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="line-359"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="line-360"><span class="sd">    Execute the training script for the ToyTransformer model.</span>
</span><span id="line-361">
</span><span id="line-362"><span class="sd">    - generates a toy dataset of scalar inputs and target sequences;</span>
</span><span id="line-363"><span class="sd">    - defines and trains a transformer model;</span>
</span><span id="line-364"><span class="sd">    - trains for a fixed number of epochs;</span>
</span><span id="line-365"><span class="sd">    - saves the learning curve and the trained model.</span>
</span><span id="line-366"><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="line-367">    <span class="c1"># Set hyperparameters</span>
</span><span id="line-368">    <span class="n">N_SAMPLES</span> <span class="o">=</span> <span class="mi">5000</span>
</span><span id="line-369">    <span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">10</span>
</span><span id="line-370">    <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
</span><span id="line-371">    <span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="line-372">    <span class="n">LR</span> <span class="o">=</span> <span class="mf">1e-3</span>
</span><span id="line-373">
</span><span id="line-374">    <span class="n">dataset</span> <span class="o">=</span> <span class="n">ToyDataset</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N_SAMPLES</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>
</span><span id="line-375">    <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="line-376">
</span><span id="line-377">    <span class="n">model</span> <span class="o">=</span> <span class="n">ToyTransformer</span><span class="p">(</span>
</span><span id="line-378">        <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span><span id="line-379">        <span class="n">nhead</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="line-380">        <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="line-381">        <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="line-382">        <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
</span><span id="line-383">        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="line-384">        <span class="n">max_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span>
</span><span id="line-385">    <span class="p">)</span>
</span><span id="line-386">    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="line-387">    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-388">
</span><span id="line-389">    <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
</span><span id="line-390">    <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
</span><span id="line-391">    <span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
</span><span id="line-392">
</span><span id="line-393">    <span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-394">    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
</span><span id="line-395">        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span id="line-396">        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="line-397">        <span class="k">for</span> <span class="n">x_loader</span><span class="p">,</span> <span class="n">y_pad_loader</span><span class="p">,</span> <span class="n">mask_loader</span><span class="p">,</span> <span class="n">length</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
</span><span id="line-398">            <span class="n">x</span><span class="p">,</span> <span class="n">y_pad</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="line-399">                <span class="n">x_loader</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
</span><span id="line-400">                <span class="n">y_pad_loader</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
</span><span id="line-401">                <span class="n">mask_loader</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
</span><span id="line-402">            <span class="p">)</span>
</span><span id="line-403">            <span class="n">stop_target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">MAX_LEN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="line-404">            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">L</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
</span><span id="line-405">                <span class="n">stop_target</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">L</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="line-406">            <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="line-407">            <span class="n">y_hat</span><span class="p">,</span> <span class="n">stop_logits</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward_teacher</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_pad</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span><span id="line-408">            <span class="n">mse_elements</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_pad</span><span class="p">)</span>
</span><span id="line-409">            <span class="n">mask_f</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="line-410">            <span class="n">valid</span> <span class="o">=</span> <span class="n">mask_f</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="line-411">            <span class="n">mse</span> <span class="o">=</span> <span class="p">(</span><span class="n">mse_elements</span> <span class="o">*</span> <span class="n">mask_f</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">valid</span>
</span><span id="line-412">            <span class="n">stop</span> <span class="o">=</span> <span class="n">bce_loss</span><span class="p">(</span><span class="n">stop_logits</span><span class="p">,</span> <span class="n">stop_target</span><span class="p">)</span>
</span><span id="line-413">            <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span> <span class="o">+</span> <span class="n">stop</span>
</span><span id="line-414">            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="line-415">            <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="line-416">            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="line-417">        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
</span><span id="line-418">        <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>
</span><span id="line-419">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">ep</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="line-420">
</span><span id="line-421">    <span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">loss_history</span><span class="p">)</span>
</span><span id="line-422">    <span class="n">base_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span>
</span><span id="line-423">    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s2">/toy_model.pt&quot;</span><span class="p">)</span>
</span><span id="line-424">    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved in </span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s2">/toy_model.pt&quot;</span><span class="p">)</span></div>

</span><span id="line-425">
</span><span id="line-426">
</span><span id="line-427"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="line-428">    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
    </div></div>
        </main>
      </div>
    </div><footer class="py-6 border-t border-border md:py-0">
    <div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
      <div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
        <p class="text-sm leading-loose text-center text-muted-foreground md:text-left">Built with <a class="font-medium underline underline-offset-4"
    href="https://www.sphinx-doc.org"
    rel="noreferrer">Sphinx 7.4.7</a></p>
</div>
</div>
</footer>
  </div>
  
    <script src="../../../_static/documentation_options.js?v=01f34227"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script defer="defer" src="../../../_static/theme.js?v=073f68d9"></script>
  
</body>
</html>